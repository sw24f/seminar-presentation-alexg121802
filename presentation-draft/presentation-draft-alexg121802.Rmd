
---
title: "Effect sizes for paired data should use the change score variability rather than the pre-test variability:\\


A Paper by Dr. Scott Dankel and Dr. Jeremy P. Loenneke"
author: "Alex Gould"
date: "`r Sys.Date()`"
bibliography: pres.bib
output: 
  beamer_presentation:
    keep_tex: true  
    pandoc_args: [
      "--variable", "aspectratio=169"  # Set aspect ratio directly
    ]
header-includes:
  - \usepackage{amsmath}
  - \usepackage{graphicx}
  - \usepackage{booktabs}
  - \usepackage{setspace}
  - \usepackage{float}
  - \usepackage{hyperref}
  - \setbeamersize{text margin left=0.25in, text margin right=0.25in}
---


# Full Citation
Dankel, SJ and Loenneke, JP. Effect sizes for paired data should use the change score variability rather than the pre-test variability. J Strength Cond Res 35(6): 1773–1778, 2021—}


# What is effect size 
  - Variable that provides an overall measure for magnitude of change (@dankeleffect)
  - Differs from a T-statistic because sample size is not included
  - Quantifies how much the mean of the post-treatment differs from the mean of the baseline score
  in terms of a certain standard deviation.
    - Specifically, they are looking at this comparison from the lens of meta-analyses for exercise science and sports medicine


# Authors' Aims

- To convince the audience through analysis that baseline and post-test standard deviations (study sample measures of variability) don't tell the full story on the overall variability of the intervention. 
- To convince the readers that the heterogeneity of the study sample can play a part in unintentionally influencing effect size measurements.

How would one describe the two types of aforementioned variability?


# Variability of the Study Sample
- Any measure of difference between subjects in a given treatment group
- Represented by the Baseline and Post-treatment Standard Deviation. 
- @dankeleffect and his team claim that the use of this type of variability in paired-sample studies is useless as it has nothing to do with the treatment itself


# Variability of the Intervention
- Any measure of difference between baseline and post-treatment measure
- Represented in this case by the Standard Deviation of Change Scores (I will elaborate on this later)
- Dankel and his team prefer this method of assessing variability 


# Dr. Scott Dankel
- Professor at Rowan University, a public research university in New Jersey
- Attended the University of Mississippi to pursue a Masters and PhD in Exercise Science
- Research Interests include acute and chronic adaptations to blood flow restricted exercise  [@dankelintro]


# Dr. Jeremy Paul Loenneke
- Professor at The University of Mississippi
- Attended Southeast Missouri State for his Bachelors and Masters in Nutrition and Exercise Science
- Eventually got his PhD in Exercise Physiology at the University of Oklahoma
- Research Discipline is in Skeletal Muscle Plasticity [@loennekeintro]


- Regarding the disciplines of the authors, this paper was published in The Journal of Strength and Conditioning Research. This is a good example of the use of statistics as an interdisciplinary tool 


# Introduction

## Specific Effect Size Measures

The author's claim that the common effect size measures listed below are used exhaustively in meta-analyses in the exercise science discipline. 

  - Cohen's d (Cite)
  - Hedge's g (Cite)
  - Glass delta (Cite)
  
  
  - Each use some combination of baseline standard deviation and post-treatment standard deviation.
  - Measures of variability of the study sample


# Paired Data vs. Independent Data

## Independent Data
  - Data collected through an Independent design
    - Each subject is only measured once
    - Subjects are allocated into a baseline group and a post-treatment group
    - Study sample variability is more important 
    - The pooled standard error is the way to assess this variability

## Paired Data
  - Data that is collected through a Paired Sample design 
      - Same subject is assessed at both time points. 
      - Since its based on the same subject, this data is not independent
      - In this type of Design, study sample variability is irrelevant
      - Variability of assessed by standard error of the change scores

Since most meta-analysis data is paired, Dankel's analysis focuses on primarily paired-sample designs. Therefore, the authors believe that intervention variability is the best measure for this specific analysis. 


# Methods 

## Preliminary measures
$$
M_{change}=\text{Difference between means of Posttreatment group and baseline group in an independent design }
$$
$$
SD_{bsl}={\text{Standard Deviation of the baseline group in an independent design}}
$$
$$
SD_{post}={\text{Standard Deviation of the posttreatment group in an independent design}}
$$
$$
n_{bsl}= \text{The sample size of the baseline group}
$$
$$
n_{post}= \text{The sample size of the posttreatment group}
$$

$$
SD_\text{pooled}=\sqrt{\frac{(n_{\text{bsl}}-1)SD_{\text{bsl}}^2+(n_{\text{post}}-1)SD^2_{\text{post}}}{
n_{\text{bsl}}+n_{\text{post}}-2}}
$$

# Calculations of Common Effect Size measures 

$\text{Cohen's } d= \frac{M_\text{change}}{SD_\text{pooled}}$

$\text{Glass's } \delta = \frac{M_\text{change}}{SD_{\text{bsl}}}$

$\text{Hedge's }g= C*\frac{M_\text{change}}{SD_\text{pooled}}$

Where $C$ is a factor depending on $n$ multiplied to account for small sample sizes

We can calculate an Independent $t$ test statistic: 

$T_\text{indep}= \frac{M_{\text{change}}}{\sqrt{SD_{\text{pooled}}(\frac{1}{n_\text{bsl}}+\frac{1}{n_{\text{post}}})}}$

Where $d$ represents Cohen's $d$. From this it is apparent how using the incorrect effect size can be detrimental to a given analysis when using a Paired Design.  

# Analysis and Procedure
- 1st figure shows ...
- 2nd figure shows ... 

# Figure 1 

*paste figure*
briefly explain A,B,C

# Figure 2

*paste figure*
briefly explain A,B,C

# Results (Dankel et. al)
paste bottom of fig1 and fig2 and explain results and what went wrong .
- mention that 11.618 makes no sense as an effect size measure 

# My Results 
Recalculate Cohen's dz and show if it changes the significance at all. 
mention: $SD_\text{change}`=\sqrt{SD_{\text{pre}}^2+SD_{\text{post}}^2-2rSD_{pre}SD_{post}}$ this is the formula used in the article

# Discussion
##General
Impossible to quantify variability of actual intervention when using pre-post scores 

Figure 1: Intervention 1 produces positive effect where intervention two does not 

Common effect size measures are reliant on the heterogeneity of the study population 

Figure 2 shows identical results in 2 diff groups with the only difference being that intervention 1 used a more heterogeneous population 

##Other Issues/Notes
Notes: normalizing using the preSD only is dependent on the subjects recruited rather than effectiveness 

Also used in triangulation when trying to obtain sample size calculations  


# Any Questions? 

# References 

